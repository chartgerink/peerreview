The submitted manuscript replicates survey work on questionable research practices in empirical sciences, after initial work by John, Loewenstein, and Prelec (2012) and Agnoli, Wicherts, and Veldkamp (2017). I welcome this contribution from ecology and evolution perspectives after I just recently heard increasing concerns from people in my network about this field. I think this is worthwhile work, but I am only here to assess the rigorousness of the work 💁 As such, I outline some of my (larger) concerns/suggestions below.

* The data disclosure statement indicates part of the data will be openly available but qualitative information won't without an agreement. I would suggest actually formulating this agreement to provide readers with clear information of the terms to get access (otherwise it's a fruitless exercise). Additionally, as a reviewer it seems like I can just view all these qualitative information in the data. As such, the data files provided upon submission are not the files that will be shared for the quantitative data, hence, I cannot sign off on these in its current form. I do sign off that the underlying data of the results presented in the paper are in those files provided.  

* In the introduction the authors talk about publication bias and QRPs, but provide little indication of previous research on publication bias in ecology. I think this would help contextualize the paper a bit more and suggest the authors include this and make this paper more domain specific.

* The authors say all analyses are pregistered, please indicate that this was done before analysis and not before data collection. Inspecting the preregistration indicates that the authors were halfway through data collection on 2017-07-26, but the manuscript says the survey ran through July 2017. It seems like this is conflicting and I would like to hear more about whether the end date in the MS is incorrect, the description in the preregistration was too optimistic, why I am wrong, or otherwise. Moreover, I'd like to note that it was not clear to me until just before submitting this review that the preregistration was only viewable with "View registration form". The files included in the OSF project contain no information on the preregistration, hence, I thought the preregistration was insufficient (I am glad I found out and have let the OSF know). Considering the analyses presented in the manuscript, I actually find preregistration of analyses somewhat unnecessary because the authors take a primarily descriptive approach and have formulated loose predictions that are not tested anyway.

* The results section is very interesting; the contrasts with the John et al (2012) and Agnoli et al (2017) results is worthwhile. I am wondering whether the authors have any conception about the country of origin of the authors and relating that to the results? I checked the data but there is no information on country, so I guess I can only speculate. Considering that John - Agnoli is a culturally different sample, while this sample also varies the domain, it seems like something worthwhile discussing.

* Do the authors think selecting for the highest JIFs could have inflated the QRP rates due to the high rejection rates for these journals? It seems like this is something worth discussing.

* The authors describe the survey as being sent between November 2016 and July 2017. That is quite a long period of time --- could the authors expand a bit on why this is the case and whether there could have been a time effect? (depending on the discussion of these topics in ecology and evolution domains)

* I find it really difficult to understand the structure and flow of Table 4. I would prefer a clearer caption to guide me as reader or a restructuring to make this more logical. I understand the authors want to communicate a lot of information, but this is somewhat confusing.

* It is one of my personal pet peeves to read discussions in meta-research that follow the rhetoric of "this is a problem, don't do this anymore and it won't be a problem any longer." The solutions section seems to do this. What kind of social, cultural, and other factors do the authors see as being barriers to change? I would love to hear more of their thoughts on this, considering they read all the qualitative information in the survey. For example, the solution preregistration is subject to cultural uptake. What barriers do the authors identify and how would they suggest tackling them (e.g., suggestions for interventions)?

I did not review S2+3. I tried to reproduce the plots and results, but line 557 of the provided code does not work and breaks all subsequent plots. All in all, I think this manuscript presents worthwhile data on QRPs in a different domain, but the manuscript can benefit from a more in-depth take on the underlying issues and ways to make progress.

I always sign my reviews 🖋
Chris Hartgerink

Minor things
* Non-significant => nonsignificant?
* There are special characters in the EvBiolResponses.csv that give error upon reading in of data
